---
title: "Project Luther 2.1: Beautiful(Ugly)Soup"
tags:
  - wine
  - BeautifulSoup
  - webscraping
---

Once I had basic idea of what I wanted to do, the next step was to obtain data. 

From where?

From everywhere!

Idea of scraping the data from the web was new to me, and I was really excited about it - until I actually had to do it myself.

There were 3 pieces of information I needed to scrape:

1. [US GDP](http://www.multpl.com/us-gdp-inflation-adjusted/table?f=m)
2. [Wine](www.wine-searcher.com)
3. [Weather](www.wunderground.com)

#1 was quite easy. Once I souped the url, I looked for data table, and extracted the values I needed.

Then the road got quite bumpy for #2 and #3. 

For the 10 most popular wine types, I went to a the corresponding page which then had a list of popular wines. Of those, I decided to get the names, links, and regions of first 125 wines. Because there were only 25 wines in each page, I had to go to the next page to get the next 25 until my list of wines for a given wine-type was filled to 125. That’s already 50 pages that I need to soup. But the problem is that this site did not allow souping immediately. So I had to resort to a slower option of using Selenium to get to each specific page, then souping. But perhaps even this was being ambitious because my IP address was soon blocked! So to go around this, specified chrome-option on the webdriver to use different IP addresses. To add insurance to not get blocked, I even rotated around these addresses after souping some number of pages and even added some random time delay (1-10 seconds, which definitely increased the process time significantly). Now once I had the list of all the wines, I went to each link using Selenium, looked for a button “Market Data” and got the driver to click it. Then soup time! Though not always the case, the market data page generally had information on average price and average score for some range of year. (Note that the year value here is used as key to merge with GDP dataset). Again, while I was detecting some off-patterned pages, IP addresses were getting blocked from time to time, so I had to keep an eye out. 

Souping weather site was just as tricky because of couple issues:
1. For a given region, specified region is not in the weather database
2. Even if the location is in the database, it may not have a value for the specified monthly history data.
3. There are many multiple cities with the same name, but the wine website does not specify which state is in. For example, region may be “Rutherford, USA”. But there is no way to figure out which one of 12 states this may be referring to.
So the weather data availability was what ultimately determined the size of the data.
